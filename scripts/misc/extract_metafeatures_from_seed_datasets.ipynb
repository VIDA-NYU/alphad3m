{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Script\n",
    "\n",
    "The following cell contains utility functions that use the metalearn package from BYU to extract meatafeatures from datasets. Please install the requirements in the root folder of this repository or at least the metalearn pakcage via \n",
    "\n",
    "```\n",
    "   pip install git+https://github.com/byu-dml/metalearn.git#egg=metalearn\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "from json import loads, dumps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from metalearn.metafeatures.simple_metafeatures import SimpleMetafeatures\n",
    "from metalearn.metafeatures.statistical_metafeatures import StatisticalMetafeatures\n",
    "from metalearn.metafeatures.information_theoretic_metafeatures import InformationTheoreticMetafeatures\n",
    "\n",
    "def load_dataframe(training_set, data_format=\"dict\"):\n",
    "    df = pd.read_csv(training_set)\n",
    "    #df.fillna('', inplace=True)\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    X =  df.values[:,0:-1]\n",
    "    Y = df[df.keys()[-1]].astype('str').as_matrix()\n",
    "    print('Y ', Y)\n",
    "    Y = df.filter([df.keys()[-1]]).astype('str').values.flatten()\n",
    "    print('Y ', Y)\n",
    "    attributes = []\n",
    "    for i in range(0,len(X[0])):\n",
    "        attributes.append((df.keys()[i],str(type(X[0][i]))))\n",
    "    attributes.append(('class', list(set(Y))))\n",
    "    return X, Y, attributes\n",
    "\n",
    "def extract_metafeatures(X,Y,attributes):\n",
    "    metafeatures = {}\n",
    "    features, time = SimpleMetafeatures().timed_compute(X,Y,attributes)\n",
    "    print(\"simple metafeatures compute time: {}\".format(time))\n",
    "    total_time = time\n",
    "    for key, value in features.items():\n",
    "        metafeatures[key] = value\n",
    "\n",
    "    features, time = StatisticalMetafeatures().timed_compute(X,Y,attributes)\n",
    "    print(\"statistical metafeatures compute time: {}\".format(time))\n",
    "    total_time = total_time + time\n",
    "    for key, value in features.items():\n",
    "        metafeatures[key] = value\n",
    "\n",
    "    features, time = InformationTheoreticMetafeatures().timed_compute(X,Y,attributes)\n",
    "    print(\"information theoretic metafeatures compute time: {}\".format(time))\n",
    "    total_time = total_time + time\n",
    "    for key, value in features.items():\n",
    "        metafeatures[key] = value\n",
    "\n",
    "    return metafeatures\n",
    "\n",
    "def compute_metafeatures(dataset_path):\n",
    "    X, Y, attributes = load_dataframe(dataset_path, \"dict\")\n",
    "    metadata = extract_metafeatures(X, Y, attributes)\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Seed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-d481260dfb70>, line 4)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-d481260dfb70>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    cd_command = 'cd '+path'; '\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import subprocess\n",
    "# Please change this path.\n",
    "path = '/Users/raonilourenco/D3M/'\n",
    "cd_command = 'cd '+path'; '\n",
    "#Please provide a valid token, this follwoing token is for rlourenco\n",
    "token = 'IcrgDrcQpmOdHxO0BSaW8tzHP9HZvhyMiA8TAqssrdxrVWze2NlPvlccgu3XVQ2t'\n",
    "datasets_url = 'https://datadrivendiscovery.org/data/training_datasets/LL0/'\n",
    "wget_command = \"wget -r -np -R \\\"index.html*\\\" -nH --header \\'Authorization:%s\\' %s\"%(token,datasets_url)\n",
    "\n",
    "subprocess.call(cd_command+wget_command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting training sets files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yamuna/D3M/data/LL0/LL0_22_mfeat_zernike/LL0_22_mfeat_zernike_dataset/tables/learningData.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'learningData.csv'\n",
    "# Please change this path.\n",
    "path = '/Users/yamuna/D3M/data/LL0/LL0_22_mfeat_zernike'\n",
    "training_sets = []\n",
    "for root, dirs, files in os.walk(path):    \n",
    "    if name in files:\n",
    "        training_sets.append(os.path.join(root, name))\n",
    "#example\n",
    "training_sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y  ['1' '1' '1' ..., '10' '10' '10']\n",
      "Y  ['1' '1' '1' ..., '10' '10' '10']\n",
      "simple metafeatures compute time: 0.057614803314208984\n",
      "statistical metafeatures compute time: 14.388926982879639\n",
      "information theoretic metafeatures compute time: 2.0278217792510986\n",
      "{'/Users/yamuna/D3M/data/LL0/LL0_22_mfeat_zernike/LL0_22_mfeat_zernike_dataset/tables/learningData.csv': {'number_of_classes': 10, 'number_of_instances': 2000, 'number_of_features': 48, 'dimensionality': 0.024, 'number_of_numeric_features': 48, 'percentage_of_numeric_features': 1.0, 'number_of_nominal_features': 0, 'percentage_of_nominal_features': 0.0, 'symbols_min': 10, 'symbols_max': 10, 'symbols_mean': 10.0, 'symbols_q1': 10.0, 'symbols_q2': 10.0, 'symbols_q3': 10.0, 'symbols_sd': 0.0, 'symbols_sum': 10, 'class_prob_min': 0.10000000000000001, 'class_prob_max': 0.10000000000000001, 'class_prob_mean': 0.10000000000000001, 'class_prob_q1': 0.10000000000000001, 'class_prob_q2': 0.10000000000000001, 'class_prob_q3': 0.10000000000000001, 'class_prob_sd': 0.0, 'default_accuracy': 0.10000000000000001, 'majority_class_size': 200, 'minority_class_percentage': 0.10000000000000001, 'minority_class_size': 200, 'simple_time': 0.04795599999998501, 'skewness': 0.6368489737356942, 'skewness_prep': 0.6368489737356946, 'kurtosis': 3.6045098583324107, 'kurtosis_prep': 3.6045098583324107, 'abs_cor': 0.26458737183022207, 'cancor_1': 0.98973955164757321, 'statistical_time': 27.836506, 'class_entropy': 2.3025850929940455, 'normalized_class_entropy': 0.99999999999999978, 'attribute_entropy': 1.7910713500016391, 'normalized_attribute_entropy': 0.47050962747940028, 'joint_entropy': 3.8011604027074086, 'mutual_information': 0.29249604028827453, 'equivalent_attributes': 7.8721923576288173, 'noise_signal_ratio': 5.123403750137669, 'infotheo_time': 2.2006910000000346}}\n"
     ]
    }
   ],
   "source": [
    "training_sets_metafeatures = {}\n",
    "for training_set in training_sets:\n",
    "    training_sets_metafeatures[training_set] = compute_metafeatures(training_set)\n",
    "print(training_sets_metafeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_sets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
